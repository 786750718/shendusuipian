# Chap1 Sample Space and Probability

## Definition

### frequency of occurrence vs [subjective belief](http://m.qpic.cn/psb?/V119hAgO3eS46m/o8pVHKPz2kOmRBrFYI9D1ypLG1FHPayAiA40DEJ0Uk0!/b/dEQBAAAAAAAA&bo=lATcA5QE3AMDCSw!&rf=viewer_4)

> Patient relative vs Nurse on likelihood of a new drug's effectiveness
>
> nurse belief: willing to bet 1:1 but not  2:1 on drug working vs drug not working 

### [Objective](http://r.photo.store.qq.com/psb?/V119hAgO3eS46m/oE8MJJ1gNcCqTwjX2VS5kATWDn6MgCTwH3hwwHXAtiY!/r/dDEBAAAAAAAA) of this book and the first chapter

> art of describing uncertainty in probabilistic models
>
> skill of probabilistic reasoning 
>
> generic structure of models and basic properties

## Sets 

### basic concepts 

> set, elements, empty set, {x | x satisfies P}, subset, universal set
>
> [countably infinite set, uncountable set](http://r.photo.store.qq.com/psb?/V119hAgO3eS46m/d5OEsyYM1oN6oaHwP*eI4Ya8EQFehnS3bUvwB4hHp4o!/r/dEQBAAAAAAAA) 

### Set Operations

> [complement, union, intersection, disjoint, partition](http://m.qpic.cn/psb?/V119hAgO3eS46m/4oexonW2zo9eLScOGDBLl*IrGtqV30h0VQo25pFS3.k!/b/dDMBAAAAAAAA&bo=iARUBIgEVAQDCSw!&rf=viewer_4) 
>
> [ordered pair, Venn Diagram](http://m.qpic.cn/psb?/V119hAgO3eS46m/*tPNT1GU09OJEp8LF7DvruWuawZGMDqkR0fdy0ovIeg!/b/dDABAAAAAAAA&bo=cAQwBHAEMAQDORw!&rf=viewer_4)  

### Algebra of Sets

> [basic properties of sets relations, De Morgan's laws](http://m.qpic.cn/psb?/V119hAgO3eS46m/hZgXkn32hHUOmAkGM2XiW6uhDag6J.gOGNS2vH1.Ysk!/b/dC0BAAAAAAAA&bo=lgT6A5YE.gMDCSw!&rf=viewer_4) 
>
> how to prove De Morgan's laws



## Probabilistic Models

### Definition

> mathematical description of an uncertain situation
>
> [elements of probabilistic model](http://m.qpic.cn/psb?/V119hAgO3eS46m/WFqp7fq5E1VnX63qljbjWZxJwYmniRh8DTd.7TGPUFg!/b/dDEBAAAAAAAA&bo=sAS4BLAEuAQDCSw!&rf=viewer_4) 
>
> - sample space, outcomes, event
> - probability law: assign belief or knowledge to collective likelihood of elements of A

### Sample space and Events

> [experiment, outcomes, sample space, event](http://m.qpic.cn/psb?/V119hAgO3eS46m/*rngtZD*f4I2fqnkVuecBw.cDZARsg4iyMO4CcFH7XU!/b/dDIBAAAAAAAA&bo=ggSYA4IEmAMDCSw!&rf=viewer_4)  
>
> finite and infinite number of outcomes 

### Choosing an appropriate sample space

> [elements to be distinct and mutually exclusive](http://m.qpic.cn/psb?/V119hAgO3eS46m/3qhvBdfOWuRv20c0oa9ENFU8LQitxENdDMe39y8lFYE!/b/dDEBAAAAAAAA&bo=cgTUA3IE1AMDCSw!&rf=viewer_4) 
>
> all outcomes are collectively exhaustive, avoiding irrelevant details
>
> [example](http://m.qpic.cn/psb?/V119hAgO3eS46m/HJrxkvEMMr6k62Vm.KjIGMxJaN4gxREaIA6XNDiHmuA!/b/dDMBAAAAAAAA&bo=lgRYAZYEWAEDCSw!&rf=viewer_4) on seemingly similar two experiments with different sample spaces 

### Sequential Models

> experiments have inherently sequantial character
>
> [tree-based sequential descriptor](http://m.qpic.cn/psb?/V119hAgO3eS46m/INhWy55xWHRSHfYA6mI3AiEtlOb30NwOPQhDIZy9.34!/b/dEEBAAAAAAAA&bo=YgTcBGIE3AQDCSw!&rf=viewer_4)  

### Probability Laws 

> assign probability to outcome or event A 
>
> [P(A) must satisfy following 3 axioms](http://m.qpic.cn/psb?/V119hAgO3eS46m/ZO6QNeNIWqbYOqiEVHK8ic6LKqszx13GzZGkAaE7zFw!/b/dC0BAAAAAAAA&bo=ZgQeBWYEHgUDCSw!&rf=viewer_4) 
>
> [other derived properties](http://m.qpic.cn/psb?/V119hAgO3eS46m/YO*c5pz8o09u2ADFNn34m5y3.8k1lu3NDGkFXRJAOjE!/b/dEABAAAAAAAA&bo=eATgBHgE4AQDORw!&rf=viewer_4) 

### Discrete Models

> common sense models, e.g., experiment with a single coin toss
>
> - its sample space and all possible events 
>
> [experiment with 3 coin tosses](http://m.qpic.cn/psb?/V119hAgO3eS46m/5ycaqKoSnruZNABw9ZA2pk98qtGSmvyDMaX7cvJeLBk!/b/dDEBAAAAAAAA&bo=fATWBHwE1gQDCSw!&rf=viewer_4) 
>
> - sample space and certain events 
>
> [Discrete Probability Law, Discrete Uniform Probability Law](http://m.qpic.cn/psb?/V119hAgO3eS46m/gR2NQfRis4toL0b4Uqv57QXSNAcjTAGhUPeoMugfveg!/b/dGcBAAAAAAAA&bo=cAQiBXAEIgUDORw!&rf=viewer_4) 
>
> - [example](http://m.qpic.cn/psb?/V119hAgO3eS46m/FAVcoOLi4xgW6NPVISMNMskdaI3aBY9aguHBpXIBJgQ!/b/dFUAAAAAAAAA&bo=WASeBFgEngQDCSw!&rf=viewer_4) 

### Continuous Models

> [why P(A = {a single value}) = 0](http://m.qpic.cn/psb?/V119hAgO3eS46m/f.QKqPOxKKuEmsXB*Hg88IIK4dTK*YCsGeHR6JYVz0I!/b/dEcBAAAAAAAA&bo=fgQ0BH4ENAQDCSw!&rf=viewer_4) for continuous variable
>
> [example](http://m.qpic.cn/psb?/V119hAgO3eS46m/7TJ7OBP77hDgd*fjWhr1p7j6g6fDltVUdkpyGKhpU1Y!/b/dDABAAAAAAAA&bo=SgR8BEoEfAQDORw!&rf=viewer_4): date delay span 1 hour and wait no more than 15m, P(meet)?

### Properties of Probability Laws

> [deduced](http://m.qpic.cn/psb?/V119hAgO3eS46m/QLJLn5FA5cJNN.uCJ1AJxUDaWOttsg*Gh0sOSU**uc8!/b/dFoAAAAAAAAA&bo=dgTWBHYE1gQDORw!&rf=viewer_4) more properties from 3 axioms
>
> [Venn Diagram proof on new properties](http://m.qpic.cn/psb?/V119hAgO3eS46m/EqyNTNnoZWrU7oDUvloGNAZ0tJ2OKdBLqw4cHnkHnXI!/b/dDEBAAAAAAAA&bo=HARqBRwEagUDCSw!&rf=viewer_4)  

### Models and Reality

> [art of constructing a probabilistic model with a probability law first](http://m.qpic.cn/psb?/V119hAgO3eS46m/OYmVomD9nFXBr.xTKOaM5ftps5hLLSj5Pxr4DWAifrI!/b/dGYBAAAAAAAA&bo=YAR0A2AEdAMDCSw!&rf=viewer_4) 
>
> [art of derivation](http://m.qpic.cn/psb?/V119hAgO3eS46m/6XudKjzAo5qsAa8cRwu9*kWgDY5hAGBwJfLSy1rlQuI!/b/dEABAAAAAAAA&bo=XAQoBFwEKAQDSWw!&rf=viewer_4) on probabilities of certain events
>
> [Bertrand's paradox](http://m.qpic.cn/psb?/V119hAgO3eS46m/g2iG4gbjn76j*eRP2hKTL2tuur0L1IPAVFoUsBtevbQ!/b/dEMBAAAAAAAA&bo=OgQoBToEKAUDSWw!&rf=viewer_4): same question, different perspective, different solution 1/2 vs 1/3

### A [brief history](http://m.qpic.cn/psb?/V119hAgO3eS46m/UZ8ILZJeOtTapckm1DaW00Ni5WpE1fqxTMdAdXEpDdQ!/b/dDIBAAAAAAAA&bo=qgI.BKoCPgQDCSw!&rf=viewer_4) of probability

> from B.C.E games of chance to 16th century Girolamo Cardano first book on games of chance
>
> to 17th century correspondences between Fermat and Pascal
>
> to 18th century Bernoulli on first law of large numbers and De Moivre on normal distribution and central limit theorem
>
> to 19 century Laplace and other to bring math rigor into probability and sciences 
>
> to 20 century probability become to rely on logic and pervasive in sciences and engineerings 

## Conditional Probability 

### Definition and Examples 

> to reason about outcome based on partial information 
>
> [examples](http://m.qpic.cn/psb?/V119hAgO3eS46m/STNLwmlcvpEM0ws.TSP.6I4w9F0fEPh4E*iSzhKmMzk!/b/dC0BAAAAAAAA&bo=0gRyA9IEcgMDCSw!&rf=viewer_4) on rolling two dies, word guessing, diagnose, radar screen
>
> seek to [construct new prob law given new available knowledge](http://m.qpic.cn/psb?/V119hAgO3eS46m/HB3c6OajfLhLtmG2QfFdTltTK4d0NKrjFL5GXopi5Mw!/b/dIMAAAAAAAAA&bo=qARKBagESgUDORw!&rf=viewer_4)  
>
> assumption P(B) > 0, for P(A|B) = P(A ^ B)/P(B)

### Conditional Probabilities specify a probability law

> [3 axioms works](http://m.qpic.cn/psb?/V119hAgO3eS46m/m*W1UCwHDc*CWYDupagNgrRCsWQxFIp4wvSJoRFg9*Y!/b/dDABAAAAAAAA&bo=ogQ4BaIEOAUDCSw!&rf=viewer_4) and other common properties work too
>
> view P(A|B) as [P(A) inside sample space B](http://m.qpic.cn/psb?/V119hAgO3eS46m/LIpHZSEvILjdPAd9Y6TLeo.Pr2zeEfw25B3Xv*USqXU!/b/dGYBAAAAAAAA&bo=oAQiBaAEIgUDORw!&rf=viewer_4)  
>
> [exercise 1.6](http://m.qpic.cn/psb?/V119hAgO3eS46m/DM8Wepp5Rm.IERZorMc9sVqrS5f1CF99T4WCGC3CayI!/b/dDEBAAAAAAAA&bo=oATwBKAE8AQDCSw!&rf=viewer_4): coin 3 tosses, P(A={more heads than tails} | B = {1st toss is head})
>
> [exercise 1.7](http://m.qpic.cn/psb?/V119hAgO3eS46m/h0waaXqIgRM7QX51*jiHsVWPQ3jtARaeNvwXkmVUKJU!/b/dFcAAAAAAAAA&bo=bgRIBW4ESAUDORw!&rf=viewer_4): P(A={max(X,Y)=m} | B = {min(X,Y)=2}), 4-sided die twice
>
> [exercise 1.8](http://m.qpic.cn/psb?/V119hAgO3eS46m/7Y9yQOHSigXGTUEt4T0WxHioEjy1YkJuxI8kFL69*Cs!/b/dAgBAAAAAAAA&bo=RARmBUQEZgUDORw!&rf=viewer_4): P(team N win | one out of two teams win)

### Using Conditional Probability for Modeling

> [moral](http://m.qpic.cn/psb?/V119hAgO3eS46m/4pn7wkQcXHJyyVNAB6kaBfss9uQpBN7cWsI5WdOU8NA!/b/dDABAAAAAAAA&bo=agQYBWoEGAUDCSw!&rf=viewer_4): in reality often first specify conditional prob then find out unconditional prob
>
> [example 1.9](http://m.qpic.cn/psb?/V119hAgO3eS46m/QVb8cgmEBn3UrCjygwIZ0kjyq10PIUxIznwQgIdEqFE!/b/dFYBAAAAAAAA&bo=IgTSBCIE0gQDORw!&rf=viewer_4): Radar Detection, conditional probs are given, seek unconditional joint probs 
>
> [multiplication rule](http://m.qpic.cn/psb?/V119hAgO3eS46m/loiyDxXwCc4OKJcS.k6OqXoJydtwdn0MxXMyCDQEpCY!/b/dDABAAAAAAAA&bo=VgTUBFYE1AQDCSw!&rf=viewer_4): how to use tree-based sequential descriptor in 3 steps  
>
> [example 1.10](http://m.qpic.cn/psb?/V119hAgO3eS46m/tOJfsb5No6J4adH2Xwpp5zJsKpDvvRxiamtOjc9PO9c!/b/dDMBAAAAAAAA&bo=MgQ.BTIEPgUDCSw!&rf=viewer_4): P(card no heart ^ card no heart ^ card no heart) use rule above, and a typo error in [the tree solution](http://m.qpic.cn/psb?/V119hAgO3eS46m/B*YYlX**EX0bzA2BUA.fqFzLTAJXP1wgqJG7aNCRjDU!/b/dFUAAAAAAAAA&bo=MgRSAzIEUgMDGTw!&rf=viewer_4) 
>
> [example 1.11](http://m.qpic.cn/psb?/V119hAgO3eS46m/Lo4NP96uNzU.2wq0UAjhU*eRKMUUP6nhbAgbsaYcUTU!/b/dC8BAAAAAAAA&bo=MgRyAzIEcgMDCSw!&rf=viewer_4): P(each of 4 graduates in different 4 groups), 4 graduates and 12 undergraduates in total into 4 groups; 
>
> - [==very strange way==](http://m.qpic.cn/psb?/V119hAgO3eS46m/C1t8FHHYJCNCVs83Zio6*F83T7pdvk60X3P.JUCDvgI!/b/dEEBAAAAAAAA&bo=OgQeBDoEHgQDGTw!&rf=viewer_4) of view each conditional prob???
>
> example 1.12: Monty Hall Problem
>
> - [traditional approach](http://m.qpic.cn/psb?/V119hAgO3eS46m/kVKyiAxIAGx*phWuYyPOjlDOx.BCcYfI.YfAGvgLETE!/b/dPMAAAAAAAAA&bo=iARIBIgESAQDCSw!&rf=viewer_4): reverse and step by step thinking
> - [additional approach](http://m.qpic.cn/psb?/V119hAgO3eS46m/jYHm0lWxekTrlO9*f*tcLqixmFojHpUWLn4e9SMx*rI!/b/dDMBAAAAAAAA&bo=YASYAmAEmAIDGTw!&rf=viewer_4) 

## Total Probability Theorem and Bayes' Rule

### Total Probability Theorem

> [Definition](http://m.qpic.cn/psb?/V119hAgO3eS46m/5mVpS0OkQIJTvfQcFhWARjpezA0UIXfhZMM3OVDw134!/b/dIMAAAAAAAAA&bo=2gTIA9oEyAMDCSw!&rf=viewer_4) 
>
> [Venn Diagram with Tree-diagram Explanation](http://m.qpic.cn/psb?/V119hAgO3eS46m/kDJqeIrMfqctsJ9rYYeHxQxj7q9AZ0QEcCAbdaR7gAA!/b/dGEBAAAAAAAA&bo=hAQ.BYQEPgUDORw!&rf=viewer_4) 
>
> [example 1.13](http://m.qpic.cn/psb?/V119hAgO3eS46m/q932kldZDiQGYzLwsxKO.z.YYXGeMQmVSbV8B6bfmDk!/b/dFUAAAAAAAAA&bo=cASOA3AEjgMDCSw!&rf=viewer_4): P(winning |any of 3 types of players) = P(B) 
>
> [example 1.14](http://m.qpic.cn/psb?/V119hAgO3eS46m/Hqaw0zebNsEMZkCGleTrXICrpKunhEFJKd48hLiCCiE!/b/dC0BAAAAAAAA&bo=vAQaA7wEGgMDCSw!&rf=viewer_4): P(sum of more rollings >= 4 )
>
> - fair 4-sided die, if 1 or 2, roll again otherwise stop
> - P(sum >= 4) 
> - solution: using concept of conditional probability is key
>
> [example 1.15](http://m.qpic.cn/psb?/V119hAgO3eS46m/ENp8kFRtZTz7YrqKxGMlrfaDBEGENxceDc80mRF6on0!/b/dDMBAAAAAAAA&bo=dgTaAnYE2gIDCSw!&rf=viewer_4): P(alice up-to-date class after 3 weeks)
>
> - using computer + total probability theorem is [more convenient](http://m.qpic.cn/psb?/V119hAgO3eS46m/RKtLR7ShgbzLfYx6cPP2WBneIM5lB0CmruMguUGcC58!/b/dDABAAAAAAAA&bo=cATYA3AE2AMDORw!&rf=viewer_4) than multiplication rule 

### Inference and Bayes' Rule

> [Bayes rule](http://m.qpic.cn/psb?/V119hAgO3eS46m/PknkZZl0efbdPbB*2K.cT.7sWUpUirir5PR3cjIwJ3A!/b/dDIBAAAAAAAA&bo=tgQmA7YEJgMDCSw!&rf=viewer_4) = has two parts 
>
> - conditional probability [P(A|B) $\to$ P(B|A)] + P(B) 
> - total probability theorem P(B)
> - right side = P(effect | cause) = [likelihood](http://m.qpic.cn/psb?/V119hAgO3eS46m/1XcRESXHsuG9vbqE8DF9feFeja0Np6giokvFifwAayU!/b/dDEBAAAAAAAA&bo=ogSkAqIEpAIDORw!&rf=viewer_4)
> - right side = P(Cause) = prior probability
> - left side = P(cause | effect observed) = posterior probability 
>
> [Bayes on screening cancer](http://m.qpic.cn/psb?/V119hAgO3eS46m/W6FdOBm0uYN90T1v4YWXi2EI.gxXG3tQ0b8CguQqd6U!/b/dDEBAAAAAAAA&bo=QARCBEAEQgQDKQw!&rf=viewer_4)
>
> - Bayes rule on screening effect and 3 causes 
>
> [Bayes on Radar](http://m.qpic.cn/psb?/V119hAgO3eS46m/qp87topX7fJg0KjSmSuo07jbFXEDJTSPTh5slWYE4GE!/b/dDMBAAAAAAAA&bo=WgQeA1oEHgMDCSw!&rf=viewer_4) 
>
> - P(A) = cause, P(B|A) = p(effect | cause), P(B | A^c) = get P(B)
>
> [Bayes on winning against 3 types of chess players](http://m.qpic.cn/psb?/V119hAgO3eS46m/mglJVcc1tE3gMcnbRLcOBZEc.wyshVrxBdyV78pRt.0!/b/dEMBAAAAAAAA&bo=mAT2ApgE9gIDCSw!&rf=viewer_4)
>
> - P(A = player 1) = cause 1
> - P(B | A1) = P(effect | cause 1)
>
> Bayes on [False-Positive Puzzle with disease](http://m.qpic.cn/psb?/V119hAgO3eS46m/8OT3tWM..4QbWfS8C6oeWM0OXoYmBTDSmFvAvguf7F0!/b/dDABAAAAAAAA&bo=iAQ4BAAAAAADB5I!&rf=viewer_4) 

## Independence 

### Definition and Explanation

> conditional probability, A is [Independent](http://m.qpic.cn/psb?/V119hAgO3eS46m/iTXIBeYA51QMNvVnjzNDhEtnBYX8vi00qObS9WnDoRs!/b/dDIBAAAAAAAA&bo=lgRaBZYEWgUDCSw!&rf=viewer_4) of B, A and B are independent events
>
> intuitive meaning of independence, disjoint is opposite to independence
>
> examples to test [obvious](http://m.qpic.cn/psb?/V119hAgO3eS46m/La4GuJqepXQrJ91GWbbV3U7ehRi5h7jrcJL3Dr7FNC0!/b/dGEBAAAAAAAA&bo=LgRYBS4EWAUDCSw!&rf=viewer_4) and [unobvious](http://m.qpic.cn/psb?/V119hAgO3eS46m/AgQ*cvhg3q1v25N3qJr.8RUlp3MCYyevPkQrd*6F0Cc!/b/dPIAAAAAAAAA&bo=XASUBFwElAQDGTw!&rf=viewer_4) indepdence

### Conditional Independence

> condition: C is known to occur
>
> additional knowledge: B occur or not
>
> focus on A: not affect the probability of A 
>
> [conditional independence](http://m.qpic.cn/psb?/V119hAgO3eS46m/idulsR8oxKF3YI.6jpDlWzQ4bpHYRJzEVhNoiphBpEQ!/b/dDEBAAAAAAAA&bo=dgT8BHYE*AQDCSw!&rf=viewer_4) and unconditional independence not imply each other
>
> [examples](http://m.qpic.cn/psb?/V119hAgO3eS46m/xaT7tiJSMEclgqCY6VENlCan1NQlml17jeOHqjt57Xs!/b/dFUAAAAAAAAA&bo=MgSKAjIEigIDKQw!&rf=viewer_4) for their [non-implication](http://m.qpic.cn/psb?/V119hAgO3eS46m/x3CS58xY5gd.efxYW10uOiJ500*6NFanvnzoIuqsi*4!/b/dDABAAAAAAAA&bo=TgR.BE4EfgQDORw!&rf=viewer_4) 

### Independence (collections) summary

> [summary](http://m.qpic.cn/psb?/V119hAgO3eS46m/dz6yuWL4Ybl3RHMnXE.g4NrQNEVtIittPk0LbKnEObY!/b/dDEBAAAAAAAA&bo=ZARmBWQEZgUDKQw!&rf=viewer_4) of independence and that of collection of events
>
> [pairwise independence](http://m.qpic.cn/psb?/V119hAgO3eS46m/bSdHfcEUcRN2QKesI2nUonqwEF9K3E0JuSFrt2eD6ek!/b/dDEBAAAAAAAA&bo=bASWBGwElgQDKQw!&rf=viewer_4) not imply Independence
>
> [P(A^ B ^ C) = P(A)P(B)P(C) not imply](http://m.qpic.cn/psb?/V119hAgO3eS46m/VZZpmYXgv*htnfZfqEFSmbtQgx0QbgO2pcGRrh.vPKc!/b/dGcBAAAAAAAA&bo=dARWBXQEVgUDORw!&rf=viewer_4) Independence neither 

### Reliability

> assume independence to [simplify the calculation and analysis](http://m.qpic.cn/psb?/V119hAgO3eS46m/hj9nUwog8jR5.47LbTgnu.M*xWxEHSPjyLeOeNEcpRo!/b/dDMBAAAAAAAA&bo=8gTcBPIE3AQDCSw!&rf=viewer_4)
>
> [example 1.24](http://m.qpic.cn/psb?/V119hAgO3eS46m/8MwR.bRBGwTw7KF5fzipthdwIuXVa11h0p6XAhYvgLc!/b/dDIBAAAAAAAA&bo=LgQwBS4EMAUDORw!&rf=viewer_4) Network Connectivity
>
> - P(a parallel system work)

### Independent Trials and the Binomial Probabilities

> [tree-structure makes sense](http://m.qpic.cn/psb?/V119hAgO3eS46m/*V0DDtlpoaiGtlzuNJ3HcbE*8t9.1bDnSjnqVTXqPd0!/b/dDABAAAAAAAA&bo=GgXcBBoF3AQDCSw!&rf=viewer_4) of $p^k(1-p)^{n-k}$ [not the other way around](http://m.qpic.cn/psb?/V119hAgO3eS46m/eu0YStho22JgR476Hh9i1qpbFdtQZY89R3nkL64GaPk!/b/dC8BAAAAAAAA&bo=3AQkBdwEJAUDORw!&rf=viewer_4) 
>
> n! = n balls into n positions, total combinations 
>
> n!/k! = n balls into k positions, total combinations
>
> n!/[k!(n-k)!] = n balls into k positions, and k balls are identical, total combination
>
> [how to prove binomial formula](http://m.qpic.cn/psb?/V119hAgO3eS46m/lKgsJNNpZUUgj5Ru4UQZ5vGJRBa710BXfScK8h5hewU!/b/dIMAAAAAAAAA&bo=AgUuBAIFLgQDKQw!&rf=viewer_4)? 
>
> [Example 1.25](http://m.qpic.cn/psb?/V119hAgO3eS46m/vB2tgvj0lzPHpfY7ZEP0yMeMSe*VDHkbRZlr*UY4P5A!/b/dDABAAAAAAAA&bo=2gSCA9oEggMDCSw!&rf=viewer_4) Grade of Service P(more customer needs than modems)
>
> - to select a facility size to guarantee a certain prob that no user is unserved

## Counting

### two ways of calculating P(A)

> - knowning the total number of outcomes in sample space
> - knowing each outcome's probability 
>
> art of counting is challenging ([combinatorics](http://m.qpic.cn/psb?/V119hAgO3eS46m/bvn3a21xSyfqETe8cI0ZG3GNvHJPQYhBB3ZRKmeAvTw!/b/dEcBAAAAAAAA&bo=PAVgBTwFYAUDCSw!&rf=viewer_4)) 

### The counting principle

> [Stage + Choices method](http://m.qpic.cn/psb?/V119hAgO3eS46m/8YVkhLSmKdB8h.8rxbxbZPcwb0frO81p5EYRITOSpCQ!/b/dC4BAAAAAAAA&bo=9ARkBfQEZAUDCSw!&rf=viewer_4) 
>
> [tree-structure help counting](http://m.qpic.cn/psb?/V119hAgO3eS46m/Ym6OOZ3WhzvqzQuVkWrW*Sv9PMuqAF6N*3up6uDKyi0!/b/dPIAAAAAAAAA&bo=7AQGBewEBgUDORw!&rf=viewer_4) 
>
> [Example 1.26](http://m.qpic.cn/psb?/V119hAgO3eS46m/FMvoxuFZS21lufS3Jjg4hZPNYuvXu.F529TR02ElyW4!/b/dDEBAAAAAAAA&bo=VgQwBVYEMAUDCSw!&rf=viewer_4) number of phone numbers $8 \times 10 \times 10 ...$
>
> Example 1.27 number of subsets of n-Element set $2^n$ 
>
> **permutation**: order of selection matters 
>
> **combination**: orders of selection does not matter
>
> **partition**: collection of n objects into multiple subsets

### permutation

> [k-permutation vs n-permutation](http://m.qpic.cn/psb?/V119hAgO3eS46m/KYOFJ3zajt6JEUyf9xaNueYMostjieKE.drd9FB4wxw!/b/dFUAAAAAAAAA&bo=EgWsAxIFrAMDCSw!&rf=viewer_4)  
>
> total number of words with 4 distinct letters (simple)
>
> total number of contiguous sequences from 3 types of CDs with different number for each type ([double permutation](http://m.qpic.cn/psb?/V119hAgO3eS46m/5dh5QfyN8oKORYRBJvM1rYOqu8i*m0QQYi.pQTJWJ7o!/b/dDMBAAAAAAAA&bo=9ATABPQEwAQDORw!&rf=viewer_4))  

### Combination 

> [remove duplications by k!](http://m.qpic.cn/psb?/V119hAgO3eS46m/z5cIbcYj5kF11nc7DStQ584ixGcJ8LETf78UugT2N4c!/b/dDIBAAAAAAAA&bo=DgUQBQ4FEAUDCSw!&rf=viewer_4) 
>
> number of combination of 2 out of 4 letters ([simple](http://m.qpic.cn/psb?/V119hAgO3eS46m/f7AnoOGnfclebOLIbm*Si5dbwItcgyCW6AT81WE41n4!/b/dAgBAAAAAAAA&bo=9ATIBPQEyAQDORw!&rf=viewer_4))
>
> number of combination for 1 club leader and any number of club members from n people ([complex](http://m.qpic.cn/psb?/V119hAgO3eS46m/OwlFahxSuMtYOhn1kLsBfnrBpt*.55Q0jNDkmzApk3k!/b/dDIBAAAAAAAA&bo=AgUCBQIFAgUDORw!&rf=viewer_4)) 

### Partitions

> total number of situations of putting [n balls into r groups](http://m.qpic.cn/psb?/V119hAgO3eS46m/maHkb4dMlZSy*kRSQIh*Ww*jikDUjUftf1I8HLhyJIA!/b/dFYBAAAAAAAA&bo=BgVkBQYFZAUDCSw!&rf=viewer_4) 
>
> [anagram](http://m.qpic.cn/psb?/V119hAgO3eS46m/zLpIrUxatJ6bapuOQr4M1C26dH0Fe2SEg0ZD3taityQ!/b/dDIBAAAAAAAA&bo=vgRABb4EQAUDORw!&rf=viewer_4) example 
>
> [4 graduates and 12 undergraduates](http://m.qpic.cn/psb?/V119hAgO3eS46m/2N.ylPBHEJUdvxx3SQXpD5fbOPdQWiIrLRcd8oWdC7Q!/b/dDEBAAAAAAAA&bo=2ARsBdgEbAUDKQw!&rf=viewer_4) example 

## Summary and Discussion

> [4 counting methods](http://m.qpic.cn/psb?/V119hAgO3eS46m/7YRG9SoKNo5fjDaK2D.NIbcVUnjr3PkFX5HuKlhbaGA!/b/dDEBAAAAAAAA&bo=GAUGBRgFBgUDCSw!&rf=viewer_4)
>
> 3 steps to solve a probabilistic problem 
>
> [3 methods for calculating probability](http://m.qpic.cn/psb?/V119hAgO3eS46m/S2Te4XyKZAe8bSAUHLGz.NtMdugEc4AULmKM8*IHHHM!/b/dDMBAAAAAAAA&bo=ZgQ8BWYEPAUDORw!&rf=viewer_4) 

## Problems

# Chap2 Discrete Random Variables

## Basic Concepts

> [random variable](http://m.qpic.cn/psb?/V119hAgO3eS46m/IP56eZ6fOith00mD1FWm0e9ghPd7j6FQ5EDX*nWxQo4!/b/dDEBAAAAAAAA&bo=OAR6BTgEegUDCSw!&rf=viewer_4) as function 
>
> outcomes themselves are not random variables
>
> [examples](http://m.qpic.cn/psb?/V119hAgO3eS46m/nrRcPvNixDtpzydLcM7sC2EwWEx8KCgrG0BXfPhEMSg!/b/dEcBAAAAAAAA&bo=bgRoBW4EaAUDORw!&rf=viewer_4) of random variables
>
> [discrete vs continuous](http://m.qpic.cn/psb?/V119hAgO3eS46m/vgJAqaZpGRPpuIn41Il4xo6clsym6kJ7P70aBXe*YtM!/b/dIMAAAAAAAAA&bo=WAUeBVgFHgUDORw!&rf=viewer_4) random variable def and examples
>
> [PMF](http://m.qpic.cn/psb?/V119hAgO3eS46m/1JUCsWFrasin*1EttsjlIGgk3Ojgvl82bQHplpJaJ9M!/b/dDEBAAAAAAAA&bo=RAVkBUQFZAUDORw!&rf=viewer_4) definition

## Probability Mass Functions

## Functions of Random Variables

## Expectation, mean and variance 

## Joint PMFs of Multiple Random Variables

## Conditioning

## Independence

## Summary and discussion

## Problems

# Chap3 General Random Variables

## Continuous Random Variables and PDFs

## Cumulative Distribution Functions

## Normal Random Variables

## Joint PDFs of multiple random variables

## Conditioning 

## The continuous bayes' rule

## Summary and Discussion

## Problem

# Chap4 Further Topics on Random Variables

## Derived Distributions

## Covariance and Correlation

## Conditional Expectation and Variance Revisted

## Transforms 

## Sum of a Random Number of Independence Random Variables

## Summary and Discussion

## Problem

# Chap5 Limit Theorems

## Markov and Chebyshev Inequalities

## The weak law of large numbers 

## Convergence in Probability

## The Central Limit Theorem

## The strong Law of Large Numbers

## Summary and Discussion

## Problems 

# Chap6 The Bernoulli and Poisson Processes 

## The Bernoulli Process 

## The Poisson Process

## Summary and Discussion

## Problems 

# Chap7 Markov Chains

## Discrete-Time Markov Chains

## Classification of States 

## Steady-State Behavior 

## Absorption Probabilities and Expected Time to Absorption 

## Continuous-Time Markov Chains 

## Summary and Discussion 

## Problems 

# Chap8 Bayesian Statistical Inference

## Bayesian Inference and the Posterior Distribution

## Point Estimation, Hypothesis Testing, and the MAP rule 

## Bayesian Least Mean Squares Estimation

## Bayesian Linear Least Mean Squares Estimation

## Summary and Discussion 

## Problems 

# Chap9 Classical Statistical Inference

## Classical Parameter Estimation

## Linear Regression 

## Binary Hypothesis Testing

## Significance Testing 

## Summary and Discussion 

## Problems 